{"charts/actor_avg_logstd": -0.5746294260025024, "charts/average_rew_magnitude": 0.36598533391952515, "losses/move_mean_agent=False/value_loss": 0.20391246676445007, "losses/value_loss": 0.20391246676445007, "losses/policy_loss": -0.00896918773651123, "losses/entropy": 0.8443313837051392, "losses/old_approx_kl": 0.00924301240593195, "losses/approx_kl": 0.009069203399121761, "losses/clipfrac": 0.07785807180334814, "losses/explained_variance": 0.7866749912500381, "train/value_loss": 0.20391246676445007, "train/policy_loss": -0.00896918773651123, "train/value": 1.7958873510360718, "train/adv_mean": 4.715237617492676, "train/adv_std": 9.348682403564453, "train/adv_max": 53.256011962890625, "train/adv_min": -45.593406677246094, "train/act_min": -2.5703125, "train/act_max": 2.513671875, "train/ratio_min": 0.40613579750061035, "train/ratio_max": 1.5646368265151978, "Env step": 9984000, "global_step": 9984000, "Update": 26, "FPS": 331326.0535002575, "perf/_fps": 331326.0535002575, "_timestamp": 1694560949.0431454, "_runtime": 38.315335512161255, "_step": 78, "Average Episodic Reward": 96.32293435454369, "reward/reward": 96.32293435454369, "reward/reward_min": -353.18853759765625, "reward/reward_max": 405.06451416015625, "len/len_max": 1000.0, "len/len_min": 21.0, "len/len": 489.6, "train/obs_running_std": 0.7501838207244873, "train/obs_running_mean": 0.024178581312298775, "FPS: ": 331313.2087418189, "_wandb": {"runtime": 37}}