{"charts/actor_avg_logstd": -2.5226147174835205, "charts/average_rew_magnitude": 9.977919578552246, "losses/move_mean_agent=False/value_loss": 0.0049921018071472645, "losses/value_loss": 0.0049921018071472645, "losses/policy_loss": 0.002655921969562769, "losses/entropy": -1.1037167310714722, "losses/old_approx_kl": 0.0494530126452446, "losses/approx_kl": 0.04903870448470116, "losses/clipfrac": 0.43199543841183186, "losses/explained_variance": 0.9771982356905937, "train/value_loss": 0.0049921018071472645, "train/policy_loss": 0.002655921969562769, "train/value": 0.7415531277656555, "train/adv_mean": 9.80599308013916, "train/adv_std": 18.43876075744629, "train/adv_max": 414.5469055175781, "train/adv_min": -639.0029296875, "train/act_min": -2.75390625, "train/act_max": 3.525390625, "train/ratio_min": 0.0035875297617167234, "train/ratio_max": 25.344436645507812, "Env step": 999936000, "global_step": 999936000, "Update": 2604, "FPS": 418720.3397297824, "perf/_fps": 418720.3397297824, "_timestamp": 1694566183.841907, "_runtime": 2396.209818124771, "_step": 7805, "train/obs_running_std": 0.6923185586929321, "train/obs_running_mean": 0.11459316313266754, "Average Episodic Reward": 9328.939609985351, "reward/reward": 9328.939609985351, "reward/reward_min": 401.9644775390625, "reward/reward_max": 9960.7109375, "len/len_max": 1000.0, "len/len_min": 1000.0, "len/len": 1000.0, "FPS: ": 418720.1281189343, "_wandb": {"runtime": 2395}}